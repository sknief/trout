{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a67799f",
   "metadata": {},
   "source": [
    "# Dev Skeleton\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c3505c",
   "metadata": {},
   "source": [
    "# Section 0: Prereqs and Set-up\n",
    "0.1 - Packages <br>\n",
    "0.2 - Google Colab Set-up <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940b9fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.0.1 installations\n",
    "# both % and ! can be used to install but % makes sure packages are installed in the correct environment \n",
    "%pip install torch torchvision matplotlib numpy\n",
    "%pip install cvat_reader #for local XML read-ins\n",
    "%pip install cvat_sdk cvat_sdk.pytorch #for CVAT server read-ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e60b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.1 Packages\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cvat_reader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d94ad17",
   "metadata": {},
   "source": [
    "## Section 1: Data Input\n",
    "1.1 - Read in the data files <br>\n",
    "1.2.1 - Chop the tracks into individal files <br>\n",
    "1.2.2 - Decide what tracks to keep vs not keep <br>\n",
    "1.3 - Turn these tracks into training and testing datasets <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1780ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Read in \n",
    "#two ways of doing it\n",
    "#A) Locally (downloaded xml files)\n",
    "from cvat_reader import open_cvat\n",
    "\n",
    "# Open the CVAT XML file\n",
    "dataset = open_cvat('annotations.xml')\n",
    "\n",
    "# Access images and annotations\n",
    "for image in dataset.images:\n",
    "    print(f\"Image Name: {image.name}\")\n",
    "    for annotation in image.annotations:\n",
    "        print(f\"  Label: {annotation.label}\")\n",
    "        print(f\"  Shape: {annotation.shape}\")\n",
    "        print(f\"  Points: {annotation.points}\")\n",
    "\n",
    "#B) Directly from the CVAT servers\n",
    "from cvat_sdk.api_client import CVATAPIClient\n",
    "\n",
    "# Initialize the API client (replace with your CVAT server details and credentials)\n",
    "client = CVATAPIClient('http://localhost:8080')\n",
    "client.login(username='your_username', password='your_password')\n",
    "\n",
    "# Get a specific task or project\n",
    "task = client.tasks.retrieve(id=123) # Replace 123 with your task ID\n",
    "\n",
    "# Access annotations\n",
    "annotations = task.annotations.list() \n",
    "\n",
    "# You can then iterate through 'annotations' to process the data\n",
    "for annotation in annotations:\n",
    "    print(annotation.label)\n",
    "    print(annotation.points) # For polygons, polylines, etc.\n",
    "    print(annotation.box) # For bounding boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c67d421",
   "metadata": {},
   "source": [
    "## Section 2: Generate trajectories and other information pre-CNN\n",
    "2.1 - Generate trajectories <br>\n",
    "2.2 - Generate speed (???) <br>\n",
    "2.3 - Save this information alongside ID information to a csv for R analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107ca206",
   "metadata": {},
   "source": [
    "## Section 3: LSTM_CNN\n",
    "3.1 - hmmmm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdc15b4",
   "metadata": {},
   "source": [
    "# Section 4: Output Processing + Examination\n",
    "4.1 - Not sure yet"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
